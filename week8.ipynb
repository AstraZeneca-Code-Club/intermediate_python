{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction to analysing and presenting ML data\n",
    "\n",
    "This week, we'll introduce some methods to analyse and extract information from your machine learning models, then put everything together\n",
    "to create a web app to demonstrate your machine learning models!\n",
    "\n",
    "# Part 1: Representing high-dimentional data\n",
    "\n",
    "Often with machine learning problems, we are dealing with datasets that are hard to visualise in 2 or 3 dimentions,\n",
    "for example we couldn't hope to visualise even a simple dataset containing 10 features like the housing dataset earlier.\n",
    "\n",
    "\n",
    "The most popular algorithm for dealing with this is Principle Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# boilerplate code to produce some 3d data for us to work with\n",
    "\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(4)\n",
    "m = 60\n",
    "w1, w2 = 0.1, 0.3\n",
    "noise = 0.1\n",
    "\n",
    "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "X = np.empty((m, 3))\n",
    "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
    "X[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
    "X[:, 2] = X[:, 0] * w1 + X[:, 1] * w2 + noise * np.random.randn(m)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PCA with sklearn is straightforward and hides the matrix computations for us"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# instantiate the PCA class to produce the principle n components\n",
    "# We can also pass the retained variance here e.g. 0.95\n",
    "pca = PCA(n_components=2)\n",
    "X2D = pca.fit_transform(X)\n",
    "\n",
    "\n",
    "# this has projected our 3D data onto a two dimentional plane defined by our two principle components, whilst maximising the variation in the transformed data\n",
    "\n",
    "\n",
    "# we can reconstruct our data from the PCA representation\n",
    "\n",
    "\n",
    "X3D_inv = pca.inverse_transform(X2D)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualising our dataset and the PCA projections\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ignore this bit! Just for plotting fancy bits\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "class Arrow3D(FancyArrowPatch):\n",
    "    def __init__(self, xs, ys, zs, *args, **kwargs):\n",
    "        FancyArrowPatch.__init__(self, (0,0), (0,0), *args, **kwargs)\n",
    "        self._verts3d = xs, ys, zs\n",
    "\n",
    "    def draw(self, renderer):\n",
    "        xs3d, ys3d, zs3d = self._verts3d\n",
    "        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, renderer.M)\n",
    "        self.set_positions((xs[0],ys[0]),(xs[1],ys[1]))\n",
    "        FancyArrowPatch.draw(self, renderer)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "axes = [-1.8, 1.8, -1.3, 1.3, -1.0, 1.0]\n",
    "\n",
    "x1s = np.linspace(axes[0], axes[1], 10)\n",
    "x2s = np.linspace(axes[2], axes[3], 10)\n",
    "x1, x2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "C = pca.components_\n",
    "R = C.T.dot(C)\n",
    "z = (R[0, 2] * x1 + R[1, 2] * x2) / (1 - R[2, 2])\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3.8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "X3D_above = X[X[:, 2] > X3D_inv[:, 2]]\n",
    "X3D_below = X[X[:, 2] <= X3D_inv[:, 2]]\n",
    "\n",
    "ax.plot(X3D_below[:, 0], X3D_below[:, 1], X3D_below[:, 2], \"bo\", alpha=0.5)\n",
    "\n",
    "ax.plot_surface(x1, x2, z, alpha=0.2, color=\"k\")\n",
    "np.linalg.norm(C, axis=0)\n",
    "ax.add_artist(Arrow3D([0, C[0, 0]],[0, C[0, 1]],[0, C[0, 2]], mutation_scale=15, lw=1, arrowstyle=\"-|>\", color=\"k\"))\n",
    "ax.add_artist(Arrow3D([0, C[1, 0]],[0, C[1, 1]],[0, C[1, 2]], mutation_scale=15, lw=1, arrowstyle=\"-|>\", color=\"k\"))\n",
    "ax.plot([0], [0], [0], \"k.\")\n",
    "\n",
    "for i in range(m):\n",
    "    if X[i, 2] > X3D_inv[i, 2]:\n",
    "        ax.plot([X[i][0], X3D_inv[i][0]], [X[i][1], X3D_inv[i][1]], [X[i][2], X3D_inv[i][2]], \"k-\")\n",
    "    else:\n",
    "        ax.plot([X[i][0], X3D_inv[i][0]], [X[i][1], X3D_inv[i][1]], [X[i][2], X3D_inv[i][2]], \"k-\", color=\"#505050\")\n",
    "\n",
    "ax.plot(X3D_inv[:, 0], X3D_inv[:, 1], X3D_inv[:, 2], \"k+\")\n",
    "ax.plot(X3D_inv[:, 0], X3D_inv[:, 1], X3D_inv[:, 2], \"k.\")\n",
    "ax.plot(X3D_above[:, 0], X3D_above[:, 1], X3D_above[:, 2], \"bo\")\n",
    "ax.set_xlabel(\"$x_1$\", fontsize=18, labelpad=10)\n",
    "ax.set_ylabel(\"$x_2$\", fontsize=18, labelpad=10)\n",
    "ax.set_zlabel(\"$x_3$\", fontsize=18, labelpad=10)\n",
    "ax.set_xlim(axes[0:2])\n",
    "ax.set_ylim(axes[2:4])\n",
    "ax.set_zlim(axes[4:6])\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualise the 2D projection\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, aspect='equal')\n",
    "\n",
    "ax.plot(X2D[:, 0], X2D[:, 1], \"k+\")\n",
    "ax.plot(X2D[:, 0], X2D[:, 1], \"k.\")\n",
    "ax.plot([0], [0], \"ko\")\n",
    "ax.arrow(0, 0, 0, 1, head_width=0.05, length_includes_head=True, head_length=0.1, fc='k', ec='k')\n",
    "ax.arrow(0, 0, 1, 0, head_width=0.05, length_includes_head=True, head_length=0.1, fc='k', ec='k')\n",
    "ax.set_xlabel(\"$z_1$\", fontsize=18)\n",
    "ax.set_ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "ax.axis([-1.5, 1.3, -1.2, 1.2])\n",
    "ax.grid(True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another useful application of dimentionality reduction, besides visualising your data, is reducing the complexity of your data\n",
    "whilst training.  Since the compressed representation retains the majority of the information for a particular training instance with fewer dimentions,\n",
    "it is often far quicker to train your model on the projection of your data rather than the data iselt!\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "* Below is the code (from last week) to load the mnist dataset.  Use a random forest classifier to fit the dataset, and time\n",
    "how long your model takes to train using the full training set.\n",
    "* Repeat the training but use a PCA projection of your dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Note, you can time how long this take to execute like this:\n",
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "time.sleep(5) # do nothing for 5 seconds\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# load the dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# instantiate the RF classifier\n",
    "\n",
    "# call the fit method using the train data and labels, wrapped with the timing code from above\n",
    "\n",
    "# print out how long the model training took\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# call the fit_transform method on your instantiated PCA class, passing a variance of 95% to produce your compressed datset\n",
    "\n",
    "\n",
    "# repeat the training from above using your compressed training data, compare the timings\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cool project time!\n",
    "\n",
    "As the final part of this course, I'm going to introduce one more cool python library that does cool stuff with the models we've built over the last few weeks.\n",
    "\n",
    "We're going to create some visualisations using the machine learning models we've introduced during the last few sessions.\n",
    "\n",
    "Here's one I made earlier...\n",
    "\n",
    "https://share.streamlit.io/jharrymoore/sklearn_gui/streamlit-app.py\n",
    "\n",
    "And if you want to refer to the source code later...\n",
    "\n",
    "https://github.com/jharrymoore/sklearn_gui\n",
    "\n",
    "Spend a few minutes playing around with it to get a feel for what we can do, then I'll show you how to do it.\n",
    "\n",
    "Hopefully you recognise some of the models and datasets from work we've done in the last few weeks!\n",
    "\n",
    "We'll use a python app called Streamlit which does all the frontend heavy lifting for us and creates beautiful apps programatically.  It's a really nice way to present and interact with data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions for running as an app\n",
    "Unfortunately, streamlit doesn't play nicely with colab.  To run this yourself,\n",
    "You will find all the code you need to run the app yourself in the wekk8_app folder of the repo.\n",
    "\n",
    "\n",
    "#### Instructions for running app locally\n",
    "On your local machine, enter the following at the command line (e.g. the integrated terminal in PyCharm), assuming you have a local python install, and you are in the intermediate_python directory\n",
    "\n",
    "`pip install streamlit matplotlib scikit-learn numpy pandas`\n",
    "\n",
    "`cd week8_app # make sure you are in the week8_app directory`\n",
    "\n",
    "`streamlit run app.py`\n",
    "\n",
    "Paste the resulting url into your browser and the app should run locally for you.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below I've included a minimal version of the script, with comments where you should add code to create additional functionality and features.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define some utility functions to do the underlying machine learning\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "import streamlit as st\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from typing import Dict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def get_dataset_name(dataset_name: str):\n",
    "    if dataset_name.lower() == 'iris':\n",
    "        data = datasets.load_iris()\n",
    "    elif dataset_name.lower() == 'wine':\n",
    "        data = datasets.load_wine()\n",
    "    elif dataset_name.lower() == 'breast cancer':\n",
    "        data = datasets.load_breast_cancer()\n",
    "    else:\n",
    "        raise AssertionError('Dataset must be one of the provided options')\n",
    "    # 1) Split the training data into train and test fractions for the data and labels, make sure your variable names line up with the return values!\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, data\n",
    "\n",
    "\n",
    "def add_ui_params(classifier_name):\n",
    "    params = {}\n",
    "    if classifier_name.lower() == 'knn':\n",
    "        K = st.sidebar.slider('K', 1, 15)\n",
    "        params['n_neighbors'] = K\n",
    "    elif classifier_name.lower() == 'svm':\n",
    "        c = st.sidebar.slider('C', 0.01, 10.0)\n",
    "        kernel = st.sidebar.selectbox('Kernel', ('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'))\n",
    "        params['C'] = c\n",
    "        params['kernel'] = kernel\n",
    "    elif classifier_name.lower() == 'random forest':\n",
    "        max_depth = st.sidebar.slider('Max Depth', 2, 15)\n",
    "        num_trees = st.sidebar.slider('n_estimators', 1, 100)\n",
    "        params['max_depth'] = max_depth\n",
    "        params['n_estimators'] = num_trees\n",
    "    return params\n",
    "\n",
    "def get_classifier(clf_name: str, params: Dict):\n",
    "    # 2)\n",
    "    # write a function to instantiate the model\n",
    "    # the function takes the classifier name, and the parameter dictionary\n",
    "    # You can initialise the class directly from the dictionary by passing them as key word arguments\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, X, y, metric, k_folds):\n",
    "    # 3)\n",
    "    # use cross val score to calculate the cross validation score the for model using the function's arguments\n",
    "\n",
    "\n",
    "    # use the fit method to train your model on the training data, make sure the variable names match the returned variable names!\n",
    "\n",
    "    return model, results, results.mean(), results.std()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# source code from https://github.com/jharrymoore/sklearn_gui\n",
    "\n",
    "import sklearn\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "st.title('Machine Learning GUI')\n",
    "\n",
    "st.write('Example GUI application with a machine learning backend')\n",
    "\n",
    "\n",
    "dataset_name = st.sidebar.selectbox('Select Dataset',\n",
    "        ('Wine', 'Breast Cancer', 'Iris'))\n",
    "\n",
    "st.write(f'Dataset Name: {dataset_name}')\n",
    "\n",
    "classifier_name = st.sidebar.selectbox('Select Classifier',\n",
    "                    ('KNN', 'SVM', 'Random Forest'))\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, data = get_dataset_name(dataset_name)\n",
    "\n",
    "\n",
    "st.write(f'Shape of the dataset is {X_train.shape}')\n",
    "st.write('Number of classes:', len(np.unique(data.target)))\n",
    "\n",
    "\n",
    "\n",
    "params = add_ui_params(classifier_name)\n",
    "\n",
    "\n",
    "model = get_classifier(classifier_name, params)\n",
    "\n",
    "k_folds = st.sidebar.slider('Cross Validation Folds', 2, 20)\n",
    "metric = st.sidebar.selectbox('Model performance metric', tuple(sklearn.metrics.SCORERS.keys()), index=11)\n",
    "\n",
    "\n",
    "fitted_model, accuracy, mean, std = train_model(model, X_train, y_train, metric, k_folds)\n",
    "y_pred = fitted_model.predict(X_test)\n",
    "test_set_accuracy = accuracy_score(y_test, y_pred)\n",
    "st.write('Cross validation Model Accuracy', mean)\n",
    "st.write('Test set accuracy:', test_set_accuracy)\n",
    "\n",
    "\n",
    "# plot the principle components\n",
    "\n",
    "pca = PCA(2)\n",
    "\n",
    "x_proj = pca.fit_transform(data.data)\n",
    "\n",
    "x1 = x_proj[:, 0]\n",
    "x2 = x_proj[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(x1, x2, c=data.target, alpha=0.8, cmap='viridis')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.colorbar()\n",
    "\n",
    "st.pyplot(fig)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}