{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Intermediate Python - week 6 - Machine Learning Project Part 2\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recap\n",
    "* Last time we looked at how to prepare real-world data so that it's suitable for machine learning, and we had a first look at fitting some models to the data\n",
    "\n",
    "This week:\n",
    "* I will introduce some more powerful machine learning models\n",
    "* We will look at the specific algorithms in more details and understand a little bit of what's going on under the hood\n",
    "* We will look at cross validation as a means to get more out of your training data\n",
    "\n",
    "*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleImputer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-7933b61dea41>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m num_pipeline = Pipeline([\n\u001B[1;32m---> 38\u001B[1;33m         \u001B[1;33m(\u001B[0m\u001B[1;34m'imputer'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mSimpleImputer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstrategy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"median\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     39\u001B[0m         \u001B[1;33m(\u001B[0m\u001B[1;34m'std_scaler'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mStandardScaler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m         ])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'SimpleImputer' is not defined"
     ]
    }
   ],
   "source": [
    "# recap from last time: import the training data, perform a stratified split based on housing income catergory, run the numerical and catagorical data through separate pipelines\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "np.random.seed(42)\n",
    "\n",
    "housing = pd.read_csv(\"https://raw.githubusercontent.com/AstraZeneca-Code-Club/intermediate_python/main/datasets/housing/housing.csv\")\n",
    "\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "\n",
    "\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Linear Regression models are about as straight forward as you can get - they fit a linear function that, given the input data, tries to predict the output. Whilst it's fitting, it calculates a loss metric - how far the predictions are from the actual value - and makes an adjustment to its coefficients using a gradient descent algorithm\n",
    "\n",
    "\n",
    "How a linear model works:\n",
    "* The algorithm tries to fit a function that looks something like\n",
    "$$ f(x) = a_{1}x_{1} + a_{2}x_{2} + ... + a_{n}x_{n}$$\n",
    "\n",
    "This makes the strong assumption that there is a linear relationship between the attributes of your data and the target you're predicting, so it may fail to make good predictions in many cases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A quick dive into how the algorithm 'learns' to predict from its data\n",
    "\n",
    "One of the central concepts of machine learning is the concept of a 'loss function' and an associated algorithm called 'gradient descent'.\n",
    "This is the strategy by which a model can be fitted to a dataset.\n",
    "\n",
    "![Gradient Descent Algorithm](datasets/grad_desc.png)\n",
    "\n",
    "We first need a loss function that computes how far away the model's current predictions are from the actual values.\n",
    "This is our current position on the loss surface.  Crucially, the loss function needs to be continuous and differentiable with respect to the parameters.\n",
    "From here, we use the computed derivatives to make small changes to the function's parameters, in the direction of steepest descent of the loss function.\n",
    "If all goes well, the model will find itself in the loss function's global minimum, and training is done!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "# like with the preprocessing functions, SKlearn models provide a fit and a transform method (for training and predicting respectively)\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# let's try the full preprocessing pipeline on a few training instances\n",
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compare against the actual values:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Labels:\", list(some_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "some_data_prepared"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lin_mae = mean_absolute_error(housing_labels, housing_predictions)\n",
    "lin_mae"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More advanced models - Decision Trees\n",
    "\n",
    "Decision trees algorithms, in their various flavours  and implementations, are extensively used in machine learning.\n",
    "In their most straightforward form, a decision tree simply asks a series of questions of the data and follows the tree down until it makes its prediction.\n",
    "During training the model learns how to partition the data, based on the loss function, to improve its predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Exercise set 2\n",
    "# 1) Instantiate a decision tree regressor and fit it to the training data, as we did above for the LinReg model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2) use your trained decision tree to make predicitons on the dataset\n",
    "\n",
    "# 3) calculate the mean squared error for the decision tree model and compare it to the linear regression model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Incredibly, we appear to have built a perfect machine learning algorithm - you should see zero loss for the decision tree!\n",
    "Is it too good to be true? Well...yes.  Almost always\n",
    "\n",
    "### Overfitting\n",
    "What we have seen here is the idea of overfitting.  This is where the model fits extremely well to the training data,\n",
    "but it doesn't generalise to cases outside of the test set.  This tends to happen when the data is too small (or too noisy)\n",
    " relative to the complexity of the model, so it starts the noise in the data rather than any general trend.\n",
    "\n",
    "One quick way to get a better idea of how your model is performing is to use cross validation.  Instead of training on a single block of data and testing on the held out set, CV takes the training set and splits it into k folds.  It then trains the model k times, using each fold once as the test set and the other k-1 as training data.\n",
    "This is a great way to avoid the model overfitting, and you can get an idea of the confidence in a certain performance metric, through the standard deviation calculated accross the k folds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# let's define a quick utility function to make comparing our model performance easiser\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Models\n",
    "Random forests are extremely powerful machine learning models, and they tend to be one of my 'goto' first model to try out when\n",
    "I'm first looking at a dataset.\n",
    "\n",
    "There several different implementation of the same idea, so if you want to learn more, look up the XGBoost package\n",
    "For today we'll stick the the SKlearn implementation\n",
    "\n",
    "The basic idea with a random forest is to take many different decision tree predictors, and rely on the principle of\n",
    "'wisdom of crowds' idea that random errors in each classifier will tend to cancel each other out, and the aggregated\n",
    "predictions of the ensemble of models outperforms any single model.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Exercise set 3 -\n",
    "# 1) Train a random forest regressor (look up the sklearn docs if you want to change parameters from the defaults)\n",
    "\n",
    "# 2) calcualate performance metrics the the random forest\n",
    "\n",
    "# 3) use the cross validation approach to evaluate the random forest model perfmance on 10 folds of the training data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "pd.Series(np.sqrt(-scores)).describe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning your model\n",
    "\n",
    "Once you've got a few models you think will perform well for your application, you need to find the settings - hyperparameters -\n",
    "that give optimal performance without overfitting.\n",
    "\n",
    "SKlearn has a helpful GridSearch implementation to perform this optimisation for us."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10], 'max_features': [2, 4]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 4]},\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=2,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# return the optimal hyperparameters\n",
    "grid_search.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# return the trained model\n",
    "grid_search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's look at the score of each hyperparameter combination tested during the grid search:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Exercise set 4:\n",
    "# 1) Choose some values for the parameters of the grid search from above and see if you can beat the previous best score the the RF model (don't go mad, stick to 3 params per catagory)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction to classifiers\n",
    "So far, we have focussed on a regression task, i.e. predicting a continuous value based on the data.\n",
    "This is one of two broad components of supervised machine learning.\n",
    "\n",
    "We will spend the rest of this session and the start of next look at classifiers, which follow many of the same principels, but predict a label instead of a value for the data\n",
    "\n",
    "As a toy dataset, we will use MNIST, a very popular set of 70,000 handwritten digits.  Each image is a set of monochromatic\n",
    "pixels (the data) and the label is the corresponding digit.  Our task will be to find an algorithm that can learn from patterns\n",
    "in the pixel data to predict the identity of the digit.\n",
    "\n",
    "Many of the techniques we introduce here transfer to machine learning fields like medical imaging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# segment the set into data and labels\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's look briefly at what we're working with\n",
    "\n",
    "import matplotlib.pyplot as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap=mpl.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# the data comes pre split into a 9:1 train:test ratio\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "# Get the binary classes for the train and test set labels\n",
    "y_train_5 = (y_train == 5) # true for 5s, false for anything else\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "\n",
    "sgd_clf = SGDClassifier()\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "sgd_clf.predict([some_digit])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Let's try some models.  We'll start with a binary classification task i.e. predict whether each image is/isn't a 5\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# As before, let's train our model using cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# note the change of scoring metric from MSE to accuracy\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring='accuracy')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The problem with accuracy\n",
    "\n",
    "It would appear that we've trained a pretty good model here, with ~95% accuracy!  However, as before, seemingly accurate\n",
    "machine learnig models should be approached with skepticism.  Predictably, ~90% of the training data is not a 5, so I\n",
    "could write a 'classifier' that just blindly predicts False, and it would return 90% accuracy on my training set!\n",
    "Accuracy (ratio of correct/incorrect predictions) is not such a great metric for classifiers, which is only worse when you have skewed datasets.\n",
    "\n",
    "### Confusion matrices and ROC score\n",
    "\n",
    "A much better approach is to look at the number of times members of one class were mislabeled as members of the other."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "confusion_matrix(y_train_5, y_train_pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From a confusion matrix, we can calculate the two most important metrics when determining classifier performance: precision and\n",
    "recall.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train_5, y_train_pred)\n",
    "recall_score(y_train_5, y_train_pred)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# let's run the same as before, but using \"decision function\" will return the decision scores instead of absolute predictions\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,\n",
    "                             method=\"decision_function\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.legend(loc=\"center right\", fontsize=16) # Not shown in the book\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)        # Not shown\n",
    "    plt.grid(True)                              # Not shown\n",
    "    plt.axis([-50000, 50000, 0, 1])             # Not shown\n",
    "\n",
    "\n",
    "\n",
    "recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))                                                                  # Not shown\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 # Not shown\n",
    "plt.plot([-50000, threshold_90_precision], [0.9, 0.9], \"r:\")                                # Not shown\n",
    "plt.plot([-50000, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")# Not shown\n",
    "plt.plot([threshold_90_precision], [0.9], \"ro\")                                             # Not shown\n",
    "plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                             # Not shown\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "03045a9733ea1a537ffa9104e197cb77bcebdb2c63fa862e44cbe6ef3569236d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}